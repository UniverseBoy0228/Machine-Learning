# 数学基础知识

## 1、高斯分布

> 数据：$X=(x_1,x_2,\cdots,x_N)^T=\left( \matrix{x_1^T \\ x_2^T \\ \vdots \\ x_N^T} \right)_{N*P}$
>
> 样本：$x_i\in R^P \quad x_i\sim N(\mu,\Sigma)$
>
> 参数：$\theta=(\mu,\Sigma)$ 
>
> $MLE:\theta_{MLE}=arg\max_\limits{\theta}P(X\vert\theta)$
>
> $N$维高斯分布：$P(X)=\dfrac{1}{(2\pi)^{\dfrac{p}{2}}}exp(-\dfrac{1}{2}(X-\mu)^T\Sigma^{-1}(X-\mu))$

---

> 令 $p=1,\theta=(\mu,\sigma^2)$
>
> $1$维高斯分布：$p(x)=\dfrac{1}{\sqrt{2\pi}\sigma}exp(-\dfrac{(x-\mu)^2}{2\sigma^2})$
> $$
> \begin{align*}
> \log P(X\vert\theta) &=\log\prod\limits_{i=1}^N p(x_i\vert\theta) \\
> &=\sum\limits_{i=1}^N \log{p(x_i)\vert\theta} \\
> &=\sum\limits_{i=1}^N [\log{\dfrac{1}{\sqrt{2\pi}}+\log{\dfrac{1}{\sigma}}-\dfrac{(x_i-\mu)^2}{2\sigma^2}}]
> \end{align*}
> $$
>
> * 对$\mu$的估计：
>
> $$
> \begin{align*}
> \mu_{MLE} &=arg\max\limits_\mu \sum\limits_{i=1}^N [\log{\dfrac{1}{\sqrt{2\pi}}+\log{\dfrac{1}{\sigma}}-\dfrac{(x_i-\mu)^2}{2\sigma^2}}] \\
> &=arg\max\limits_\mu \sum\limits_{i=1}^N [-\dfrac{(x_i-\mu)^2}{2\sigma^2}] \\
> &=arg\max\limits_\mu \sum\limits_{i=1}^N [-(x_i-\mu)^2]
> \end{align*}
> $$
>
> ------
>
> $$
> \begin{align*}
> &\dfrac{\partial}{\partial\mu}\sum\limits_{i=1}^N[-(x_i-\mu)^2]=\sum\limits_{i=1}^N(2(x_i-\mu))=0 \\
> &\Longrightarrow\mu_{MLE}=\dfrac{1}{N}\sum\limits_{i=1}^N x_i \quad\textcolor{red}{无偏估计}
> \end{align*}
> $$
>
> 因为$E[\mu_{MLE}]=E[\dfrac{1}{N}\sum\limits_{i=1}^N x_i]=\dfrac{1}{N}\sum\limits_{i=1}^N E[x_i]=\mu$，因此$\mu_{MLE}$为$\textcolor{red}{无偏估计}$。

---

> * 对$\sigma_{MLE}^2$的估计：
>
> $$
> \begin{align*}
> \sigma_{MLE}^2 &=arg\max\limits_\mu \sum\limits_{i=1}^N [\log{\dfrac{1}{\sqrt{2\pi}}+\log{\dfrac{1}{\sigma}}-\dfrac{(x_i-\mu)^2}{2\sigma^2}}] \\
> &=arg\max\limits_\sigma\sum\limits_{i=1}^N[\log{\dfrac{1}{\sigma}}-\dfrac{(x_i-\mu)^2}{2\sigma^2}]
> \end{align*}
> $$
>
> ---
>
> $$
> \begin{align*}
> &\dfrac{\partial}{\partial\sigma^2}\sum\limits_{i=1}^N[\log{\dfrac{1}{\sigma}}-\dfrac{(x_i-\mu)^2}{\sigma^2}]=\sum\limits_{i=1}^N[-\dfrac{1}{\sigma}+\dfrac{(x_i-\mu)^2}{\sigma^3}]=0 \\
> &\Longrightarrow\sigma_{MLE}^2=\dfrac{1}{N}\sum\limits_{i=1}^N(x_i-\mu)^2=\dfrac{1}{N}\sum\limits_{i=1}^N(x_i-\mu_{MLE})^2 \\
> &=\dfrac{1}{N}\sum\limits_{i=1}^Nx_i^2-\dfrac{1}{N}\sum\limits_{i=1}^N2x_i\mu_{MLE}+\dfrac{1}{N}\sum\limits_{i=1}^N\mu_{MLE}^2 \\
> &=\dfrac{1}{N}\sum\limits_{i=1}^Nx_i^2-2\mu_{MLE}^2+\mu_{MLE}^2 \\
> &=\dfrac{1}{N}\sum\limits_{i=1}^Nx_i^2-\mu_{MLE}^2  \quad \textcolor{red}{有偏估计} 
> \end{align*}
> $$
>
> ---
>
> $$
> \begin{align*}
> &E[x_i]=\mu \quad D[x_i]=\sigma^2 \Longrightarrow  E[x_i^2]=\mu^2+\sigma^2 \\
> &D[\mu_{MLE}^2]=D[\dfrac{1}{N}\sum\limits_{i=1}^Nx_i]=\dfrac{1}{N^2}=\dfrac{\sigma^2}{N}  \\
> &E[\mu_{MLE}^2]=\mu^2+\sigma^2-(\dfrac{\sigma^2}{N}+\mu^2)=\dfrac{N-1}{N}\sigma^2 \\
> 
> &E[\sigma_{MLE}^2]=E[\dfrac{1}{N}\sum\limits_{i=1}^Nx_i^2-\mu_{MLE}^2] \\
> &=\dfrac{1}{N}\sum\limits_{i=1}^NE[x_i^2]-E[\mu_{MLE}^2] \\
> &=\dfrac{1}{N}\sum\limits_{i=1}^NE[x_i^2]-(D[\mu_{MLE}^2]+E^2[\mu_{MLE}]) \\
> &=\dfrac{1}{N}\sum\limits_{i=1}^N(\mu^2+\sigma^2)-(\dfrac{\sigma^2}{N}+\mu^2) \\
> &=\dfrac{N-1}{N}\sigma^2
> \end{align*}
> $$
>
> 因为$E[\sigma_{MLE}^2]\neq\sigma^2$，因此$\sigma_{MLE}^2$是有偏估计，当$E[\sigma_{MLE}^2]=\dfrac{1}{N-1}\sum\limits_{i=1}^N(x_i-\mu_{MLE})^2$时，$\sigma_{MLE}^2$是无偏估计。

## 2、高斯分布的边缘概率分布和条件概率分布

> $$
> \begin{align*}
> &X\sim N(\mu,\Sigma)=\dfrac{1}{(2\pi)^{\dfrac{p}{2}}\Sigma^{\dfrac{1}{2}}}exp[(X-\mu)^T\Sigma^{-1}(X-\mu)] \\
> &X\in \R^p=\left(  \matrix{x_1 \\ x_2 \\ \vdots \\ x_p }\right)_{p*1},\mu=\left( \matrix{\mu_1 \\ \mu_2 \\ \vdots \\ \mu_p} \right)_{p*1},\Sigma=\left( \matrix{\sigma_{11}\quad\sigma_{12}\quad\cdots\quad\sigma_{1p} \\ \sigma_{21}\quad\sigma_{22}\quad\cdots\quad\sigma_{2p} \\ \vdots\quad\quad\vdots\quad\quad\quad\quad\quad\vdots \\ \sigma_{p1}\quad\sigma_{p2}\quad\cdots\quad\sigma_{pp}}  \right)_{p*p}
> \end{align*}
> $$
>
> $\textcolor{red}{定理：X\sim N(\mu,\Sigma)\Longrightarrow AX+B\sim(A\mu+B,A\Sigma A^T)}$
> $$
> \begin{align*}
> &X\sim N(\mu,\Sigma)\Longrightarrow MX\sim N(M\mu,M\Sigma M^T),NX\sim N(N\mu,N\Sigma N^T) \\
> &cov(MX,NX)=E[MX-E[MX]][NX-E[NX]]^T \\
> &=E[(MX-M\mu)(NX-N\mu)^T] \\
> &=E[M(X-\mu)(X-\mu)^T N^T] \\
> &=ME[(X-\mu)(X-\mu)^T]N^T \\
> &=Mcov(X,X)N^T \\
> &=M\Sigma N^T
> \end{align*}
> $$
> $\textcolor{red}{因此，当 X\sim N(\mu,\Sigma)时，MX\perp NX\Longleftrightarrow M\Sigma N^T=0。}$
>
> ---
>
> 令$X=\left( \matrix{x_a \\ x_b} \right)，x_a为(m*1)，x_b为(n*1)，m+n=p$
>
> 则$\mu=\left( \matrix{\mu_a \\ \mu_b} \right)，\Sigma=\left( \matrix{\Sigma_{aa}\quad\Sigma_{ab} \\ \Sigma_{ba}\quad\Sigma_{bb}} \right)$
>
> 求$P(x_a)，P(x_b\vert x_a)，P(x_b)，P(x_a\vert x_b)$
>
> 求解$P(x_a)$：
> $$
> \begin{align*}
> &x_a=\left( \matrix{I_m\quad 0} \right)\left( \matrix{x_a \\ x_b} \right)=\left( \matrix{I_m\quad 0} \right)X \\
> &\Longrightarrow E[x_a]=\left( \matrix{I_m\quad 0} \right)\mu=\left( \matrix{I_m\quad 0} \right)\left( \matrix{\mu_a \\ \mu_b} \right)=\mu_a \\
> &\Longrightarrow D[x_a]=\left( \matrix{I_m\quad 0} \right)\Sigma\left( \matrix{I_m\quad 0} \right)^T=\left( \matrix{I_m\quad 0} \right)\left( \matrix{\Sigma_{aa}\quad\Sigma_{ab} \\ \Sigma_{ba}\quad\Sigma_{bb}} \right)\left( \matrix{I_m \\ 0} \right)=\Sigma_{aa} \\
> \\
> &\Longrightarrow x_a\sim N(\mu_a,\Sigma_{aa})
> \end{align*}
> $$
> 求解$P(x_b\vert x_a)$：
> $$
> \begin{align*}
> &构造x_{b\cdot a}=x_b-\Sigma_{ba}\Sigma_{aa}^{-1}x_a\Longrightarrow x_b=x_{b\cdot a}+\Sigma_{ba}\Sigma_{aa}^{-1}x_a \\
> &x_{b\cdot a}=\left( \matrix{-\Sigma_{ba}\Sigma_{aa}\quad I_n} \right)\left( \matrix{x_a \\ x_b} \right)=\left( \matrix{-\Sigma_{ba}\Sigma_{aa}\quad I_n} \right)X \\
> &\Longrightarrow E[X_{b\cdot a}]=\left( \matrix{-\Sigma_{ba}\Sigma_{aa}\quad I_n} \right)\mu=\left( \matrix{-\Sigma_{ba}\Sigma_{aa}\quad I_n} \right)\left( \matrix{x_a \\ x_b} \right) \\
> &=-\Sigma_{ba}\Sigma_{aa}\mu_a+\mu_b\triangleq\mu_{b\cdot a} \\
> &\Longrightarrow D[x_{b\cdot a}]=\left( \matrix{-\Sigma_{ba}\Sigma_{aa}\quad I_n} \right)\Sigma\left( \matrix{-\Sigma_{ba}\Sigma_{aa}\quad I_n} \right)^{-1} \\
> &=\left( \matrix{-\Sigma_{ba}\Sigma_{aa}\quad I_n} \right)\left( \matrix{\Sigma_{aa}\quad\Sigma_{ab} \\ \Sigma_{ba}\quad\Sigma_{bb}} \right)\left( \matrix{-(\Sigma_{aa}^{-1})^T\Sigma_{ba}^T \\ I_n^T} \right) \\
> &=\left( \matrix{-\Sigma_{ba}\Sigma_{aa}\quad I_n} \right)\left( \matrix{\Sigma_{aa}\quad\Sigma_{ab} \\ \Sigma_{ba}\quad\Sigma_{bb}} \right)\left( \matrix{-\Sigma_{aa}^T\Sigma_{ba} \\ I_n} \right) \\
> &=\Sigma_{bb}-\Sigma_{ba}\Sigma_{aa}^{-1}\Sigma_{ab}\triangleq\Sigma_{bb\cdot a} \\
> \\
> &\Longrightarrow X_{b\cdot a}\sim N(\mu_{b\cdot a},\Sigma_{bb\cdot a})
> \end{align*}
> $$
> 其中$\Sigma_{bb}-\Sigma_{ba}\Sigma_{aa}^{-1}\Sigma_{ab}$被称为$\Sigma_{aa}$在$\Sigma$中的舒尔补
>
> ---
>
> 舒尔补定理：
>
> $n*n$的矩阵写成分块形式：$M=\left( \matrix{A\quad B \\ C\quad D} \right)_{n*n}$，其中$A,D$为方阵
>
> * 若$A$为非奇异的，则$A$在$M$中的舒尔补为$D-CA^{-1}B$
> * 若$D$为非奇异的，则$D$在$M$中的舒尔补为$A-BD^{-1}C$
>
> ---
>
> 证明$x_{b\cdot a}$与$x_a$的独立性：
> $$
> \begin{align*}
> &x_{b\cdot a}=\left( \matrix{-\Sigma_{ba}\Sigma_{aa}^{-1}\quad I_n} \right)X,\quad x_a=\left( \matrix{I_m\quad 0} \right)X \\ 
> &令M=\left( \matrix{-\Sigma_{ba}\Sigma_{aa}^{-1}\quad I_n} \right),\quad N=\left( \matrix{I_m\quad 0} \right) \\
> &M\Sigma N^T=\left( \matrix{-\Sigma_{ba}\Sigma_{aa}^{-1}\quad I_n} \right)\left( \matrix{\Sigma_{aa}\quad\Sigma_{ab} \\ \Sigma_{ba}\quad\Sigma_{bb}} \right)\left( \matrix{I_m \\ 0} \right)=0 \\
> &\Longrightarrow x_{b\cdot a}\perp x_a \\
> &\Longrightarrow x_{b\cdot a}\vert x_a=x_{b\cdot a}
> \end{align*}
> $$
>
> ---
>
> 因此：$x_b\vert x_a=x_{b\cdot a}\vert x_a+\Sigma_{ba}\Sigma_{aa}^{-1}x_a\vert x_a=x_{b\cdot a}+\Sigma_{ba}\Sigma_{aa}^{-1}x_a$
> $$
> \begin{align*}
> &\Longrightarrow E[x_b\vert x_a]=E[x_{b\cdot a}+\Sigma_{ba}\Sigma_{aa}^{-1}x_a]=\mu_{b\cdot a}+\Sigma_{ba}\Sigma_{aa}^{-1}x_a \\
> &\Longrightarrow D[x_b\vert x_a]=D[x_{b\cdot a}+\Sigma_{ba}\Sigma_{aa}^{-1}x_a]=D[x_{b\cdot a}]=\Sigma_{bb\cdot a} \\
> \\
> &\Longrightarrow x_b\vert x_a\sim N(\mu_{b\cdot a}+\Sigma_{ba}\Sigma_{aa}^{-1}x_a,\Sigma_{bb\cdot a})
> \end{align*}
> $$
> 同理：
> $$
> \begin{align*}
> &x_b\sim N(\mu_b,\Sigma_{bb}) \\
> &x_a\vert x_b\sim N(\mu_{a\cdot b}+\Sigma_{ab}\Sigma_{bb}^{-1}x_b,\Sigma_{aa\cdot b}) \\
> &其中：\mu_{a\cdot b}=-\Sigma_{ab}\Sigma_{bb}^{-1}\mu_b+\mu_a，\Sigma_{aa\cdot b}=\Sigma_{aa}-\Sigma_{bb}^{-1}\Sigma_{ba}
> \end{align*}
> $$

## 3、线性高斯模型

> $\textcolor{red}{给定一个高斯边缘分布p(x)和一个高斯条件分布p(y\vert x)，其中p(y\vert x)的均值是x的线性函数，协方差与x无关，则这是线性高斯模型。}$
>
> 已知：$p(x)=N(x\vert \mu,\Lambda^{-1})，p(y\vert x)=N(y\vert Ax+b,L^{-1})$，求解：$p(y)与p(x\vert y)$。
>
> $y=Ax+b+\epsilon,\epsilon\sim N(0,L^{-1}),\epsilon\perp x$
>
> 求解$p(y)$：
> $$
> \begin{align*}
> &E[y]=E[AX+b+\epsilon]=E[Ax+b]+E[\epsilon]=A\mu+b \\
> &D[y]=D[AX+b+\epsilon]=D[Ax+b]+D[\epsilon]=L^{-1}+A\Lambda^{-1}A^T \\
> &\Longrightarrow y\sim N(A\mu+b,L^{-1}+A\Lambda^{-1}A^T)
> \end{align*}
> $$
>
> ---
>
> 求解$p(x\vert y)$：
> $$
> \begin{align*}
> &构造Z=\left( \matrix{x \\ y} \right)\Longrightarrow E[Z]=\left( \matrix{\mu \\ A\mu+b} \right) \\
> &D[x]=\Lambda^{-1},D[y]=L^{-1}+A\Lambda^{-1}A^T \\
> &cov(x,y)=E[(x-E[x])(y-E[y])^T] \\
> &=E[(x-\mu)(Ax+b+\epsilon-A\mu-b)^T] \\
> &=E[(x-\mu)(Ax-A\mu)^T]+E[(x-\mu)\epsilon^T] \\
> &=E[(x-\mu)(x-\mu)^TA^T] \\
> &=E[(x-\mu)(x-\mu)^T]A^T=D[x]A^T=\Lambda^{-1}A^T \\
> &\Longrightarrow Z=\left( \matrix{x \\ y} \right)\sim N(\left( \matrix{\mu \\ A\mu+b} \right),\left( \matrix{\Lambda^{-1} \quad \Lambda^{-1}A^T \\ \Lambda^{-1}A^T \quad L^{-1}+A\Lambda^{-1} A^T} \right))
> \end{align*}
> $$
> 根据2中求解$P(x_b\vert x_a)$的方法可得：
>
> $x\vert y\sim N(\mu+\Lambda^{-1}A^T(L^{-1}+A\Lambda^{-1}A^T)^{-1}(y-A\mu-b),\Lambda^{-1}-\Lambda^{-1}A^T(L^{-1}+A\Lambda^{-1}A^T)^{-1}\Lambda^{-1}A^T)$

